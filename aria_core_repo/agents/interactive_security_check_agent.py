"""
Interactive Security Check Agent for analyzing mental/cognitive safety signals 
and providing personalized security advice or alerts.
"""

import os
import json
import logging
import re
from datetime import datetime
from typing import Dict, Any, Optional, List
from enum import Enum
from uuid import uuid4, UUID
from sqlalchemy import Column, String, Float, DateTime, Text, Enum as SQLEnum, create_engine
from sqlalchemy.dialects.postgresql import UUID as PGUUID
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy.sql import func
from openai import OpenAI
from .base_agent import BaseAgent

# Database setup
Base = declarative_base()

class ThreatType(Enum):
    BURNOUT = "burnout"
    EMOTIONAL_OVERLOAD = "emotional_overload"
    IMPULSIVITY = "impulsivity"
    COGNITIVE_FATIGUE = "cognitive_fatigue"
    STRESS_OVERLOAD = "stress_overload"
    DECISION_PARALYSIS = "decision_paralysis"
    ANXIETY_SPIRAL = "anxiety_spiral"
    NONE = "none"

class AlertLevel(Enum):
    GREEN = "green"
    YELLOW = "yellow"
    RED = "red"

class SecurityCheck(Base):
    """Database model for storing security check results and analysis."""
    __tablename__ = "security_checks"
    
    id = Column(PGUUID(as_uuid=True), primary_key=True, default=uuid4, index=True)
    input_text = Column(Text, nullable=False)
    detected_threat_type = Column(SQLEnum(ThreatType), nullable=False, default=ThreatType.NONE)
    alert_level = Column(SQLEnum(AlertLevel), nullable=False, default=AlertLevel.GREEN)
    risk_score = Column(Float, nullable=False, default=0.0)
    recommendation = Column(Text, nullable=False)
    analysis_data = Column(Text, nullable=True)  # JSON string for additional analysis details
    created_at = Column(DateTime(timezone=True), server_default=func.now())

class InteractiveSecurityCheckAgent(BaseAgent):
    """
    Interactive Security Check Agent for analyzing mental/cognitive safety signals.
    Provides personalized security advice and risk assessments.
    """
    
    def __init__(self):
        super().__init__("InteractiveSecurityCheckAgent")
        self.logger = logging.getLogger("agent.InteractiveSecurityCheckAgent")
        
        # Database setup
        self.db_url = os.getenv("DATABASE_URL")
        self.engine = create_engine(self.db_url)
        self.SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)
        
        # Create tables
        self._create_security_checks_table()
        
        # Initialize OpenAI
        self._initialize_openai()
        
        # Initialize threat detection patterns
        self._initialize_threat_patterns()
        
        self.logger.info("[InteractiveSecurityCheckAgent] Initialized with PostgreSQL database integration for security analysis")

    def _create_security_checks_table(self):
        """Create security_checks table if it doesn't exist."""
        try:
            Base.metadata.create_all(bind=self.engine)
            self.logger.info("[InteractiveSecurityCheckAgent] Security checks table ready")
        except Exception as e:
            self.logger.error(f"[InteractiveSecurityCheckAgent] Error creating security checks table: {e}")

    def _initialize_openai(self):
        """Initialize OpenAI client if API key is available."""
        try:
            openai_key = os.getenv("OPENAI_API_KEY")
            if openai_key:
                self.openai_client = OpenAI(api_key=openai_key)
                self.logger.info("[InteractiveSecurityCheckAgent] OpenAI GPT integration ready for security analysis")
            else:
                self.openai_client = None
                self.logger.warning("[InteractiveSecurityCheckAgent] OpenAI API key not found, using pattern-based analysis only")
        except Exception as e:
            self.openai_client = None
            self.logger.error(f"[InteractiveSecurityCheckAgent] Error initializing OpenAI: {e}")

    def _initialize_threat_patterns(self):
        """Initialize threat detection patterns and security recommendations."""
        self.threat_patterns = {
            ThreatType.BURNOUT: {
                'keywords': ['Ø®Ø³ØªÙ‡', 'Ú©Ø³Ù„', 'Ø§Ù†Ú¯ÛŒØ²Ù‡', 'ØªÙ…Ø§Ù… Ø´Ø¯', 'Ø¯ÛŒÚ¯Ù‡ Ù†Ù…ÛŒØªÙˆÙ†Ù…', 'burnt out', 'exhausted', 'tired', 'motivation'],
                'phrases': ['Ø§Ù†Ú¯ÛŒØ²Ù‡ Ù†Ø¯Ø§Ø±Ù…', 'Ø®ÛŒÙ„ÛŒ Ø®Ø³ØªÙ‡ Ø§Ù…', 'Ø¯ÛŒÚ¯Ù‡ Ù†Ù…ÛŒ ØªÙˆÙ†Ù…', 'ØªÙ…ÙˆÙ…Ø´ Ú©Ù†'],
                'recommendation': 'ðŸ”‹ Ø§Ø³ØªØ±Ø§Ø­Øª Ú©ÙˆØªØ§Ù‡ ÛŒØ§ ØªØºÛŒÛŒØ± ÙØ¹Ø§Ù„ÛŒØª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯'
            },
            ThreatType.EMOTIONAL_OVERLOAD: {
                'keywords': ['Ø§Ø³ØªØ±Ø³', 'Ø§Ø¶Ø·Ø±Ø§Ø¨', 'Ù†Ú¯Ø±Ø§Ù†', 'ØªØ±Ø³', 'overwhelmed', 'stressed', 'anxious', 'worried'],
                'phrases': ['Ø®ÛŒÙ„ÛŒ Ø§Ø³ØªØ±Ø³ Ø¯Ø§Ø±Ù…', 'Ù†Ú¯Ø±Ø§Ù†Ù…', 'Ø§Ø¶Ø·Ø±Ø§Ø¨ Ø¯Ø§Ø±Ù…', 'ØºØ±Ù‚ Ø´Ø¯Ù…'],
                'recommendation': 'ðŸ§˜ ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ ØªÙ†ÙØ³ Ø¹Ù…ÛŒÙ‚ ÛŒØ§ Ù…Ø¯ÛŒØªÛŒØ´Ù† Ú©ÙˆØªØ§Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯'
            },
            ThreatType.IMPULSIVITY: {
                'keywords': ['Ø§Ù„Ø§Ù†', 'ÙÙˆØ±ÛŒ', 'Ø³Ø±ÛŒØ¹', 'Ø¨Ø§ÛŒØ¯', 'Ø­ØªÙ…Ø§', 'immediately', 'urgent', 'must', 'right now'],
                'phrases': ['Ù‡Ù…ÛŒÙ† Ø§Ù„Ø§Ù† Ø¨Ø§ÛŒØ¯', 'ÙÙˆØ±ÛŒ Ø¨Ø§Ø´Ù‡', 'Ø³Ø±ÛŒØ¹ Ø¨Ø§Ø´Ù‡', 'Ø­ØªÙ…Ø§ Ø§Ù„Ø§Ù†'],
                'recommendation': 'â¸ï¸ Ù‚Ø¨Ù„ Ø§Ø² Ø¹Ù…Ù„ØŒ Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ ÙÚ©Ø± Ú©Ù†ÛŒØ¯ Ùˆ Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯'
            },
            ThreatType.COGNITIVE_FATIGUE: {
                'keywords': ['ÙÚ©Ø±', 'ØªÙ…Ø±Ú©Ø²', 'Ø°Ù‡Ù†', 'Ø­ÙˆØ§Ø³', 'ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ', 'focus', 'concentration', 'thinking', 'mental'],
                'phrases': ['Ù†Ù…ÛŒ ØªÙˆÙ†Ù… ÙÚ©Ø± Ú©Ù†Ù…', 'Ø­ÙˆØ§Ø³Ù… Ù¾Ø±ØªÙ‡', 'ØªÙ…Ø±Ú©Ø² Ù†Ø¯Ø§Ø±Ù…', 'Ø°Ù‡Ù†Ù… Ø®Ø³ØªÙ‡'],
                'recommendation': 'ðŸ§  Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ø³ØªØ±Ø§Ø­Øª Ø°Ù‡Ù†ÛŒ ÛŒØ§ ØªÙ…Ø±ÛŒÙ† Ø³Ø§Ø¯Ù‡ ØªÙ…Ø±Ú©Ø² Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯'
            },
            ThreatType.STRESS_OVERLOAD: {
                'keywords': ['ÙØ´Ø§Ø±', 'Ø§Ø³ØªØ±Ø³', 'ØªÙ†Ø´', 'pressure', 'stress', 'tension', 'burden'],
                'phrases': ['ØªØ­Øª ÙØ´Ø§Ø±Ù…', 'Ø§Ø³ØªØ±Ø³ Ø²ÛŒØ§Ø¯', 'ÙØ´Ø§Ø± Ú©Ø§Ø±ÛŒ', 'ØªÙ†Ø´ Ø¯Ø§Ø±Ù…'],
                'recommendation': 'ðŸ’ª Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø§Ø³ØªØ±Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¨Ø§ Ù…ØªØ®ØµØµ ØµØ­Ø¨Øª Ú©Ù†ÛŒØ¯'
            },
            ThreatType.DECISION_PARALYSIS: {
                'keywords': ['ØªØµÙ…ÛŒÙ…', 'Ø§Ù†ØªØ®Ø§Ø¨', 'Ù†Ù…ÛŒØ¯ÙˆÙ†Ù…', 'Ù…Ø±Ø¯Ø¯', 'decision', 'choice', 'confused', 'undecided'],
                'phrases': ['Ù†Ù…ÛŒ Ø¯ÙˆÙ†Ù… Ú†ÛŒ Ú©Ø§Ø± Ú©Ù†Ù…', 'Ù…Ø±Ø¯Ø¯ Ù‡Ø³ØªÙ…', 'ØªØµÙ…ÛŒÙ… Ù†Ù…ÛŒ ØªÙˆÙ†Ù… Ø¨Ú¯ÛŒØ±Ù…'],
                'recommendation': 'ðŸŽ¯ Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ù„ÛŒØ³Øª Ú©Ù†ÛŒØ¯ Ùˆ Ù…Ø²Ø§ÛŒØ§/Ù…Ø¹Ø§ÛŒØ¨ Ù‡Ø± Ú©Ø¯Ø§Ù… Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯'
            },
            ThreatType.ANXIETY_SPIRAL: {
                'keywords': ['Ø§Ø¶Ø·Ø±Ø§Ø¨', 'ØªØ±Ø³', 'ÙˆØ­Ø´Øª', 'Ù¾Ø§Ù†ÛŒÚ©', 'anxiety', 'fear', 'panic', 'worried'],
                'phrases': ['Ø§Ø¶Ø·Ø±Ø§Ø¨ Ø¯Ø§Ø±Ù…', 'Ù…ÛŒ ØªØ±Ø³Ù…', 'Ù¾Ø§Ù†ÛŒÚ©', 'ÙˆØ­Ø´Øª Ú©Ø±Ø¯Ù…'],
                'recommendation': 'ðŸŒ¸ ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¢Ø±Ø§Ù…Ø´â€ŒØ¨Ø®Ø´ ÛŒØ§ ØªÙ…Ø§Ø³ Ø¨Ø§ Ø­Ù…Ø§ÛŒØª Ø±ÙˆØ§Ù†ÛŒ'
            }
        }
        
        self.logger.info("[InteractiveSecurityCheckAgent] Threat detection patterns and security recommendations initialized")

    def respond(self, message: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Process security check requests and generate comprehensive analysis.
        
        Args:
            message (str): The message to analyze for security threats
            context (Dict): Optional context information
            
        Returns:
            Dict: Response containing security analysis and recommendations
        """
        try:
            self.remember(f"User: {message[:50]}...")
            
            # Analyze security threats
            analysis_result = self._analyze_security_threats(message, context or {})
            
            # Save to database
            security_check_id = self._save_security_check(
                input_text=message,
                threat_type=analysis_result['threat_type'],
                alert_level=analysis_result['alert_level'],
                risk_score=analysis_result['risk_score'],
                recommendation=analysis_result['recommendation'],
                analysis_data=analysis_result.get('analysis_data', {})
            )
            
            # Format response
            response_content = self._format_security_response(analysis_result, security_check_id)
            
            # Remember the analysis
            self.remember(f"Security analysis: {analysis_result['alert_level'].value} (risk: {analysis_result['risk_score']:.1f})...")
            
            return {
                'response_id': f"security_{security_check_id}",
                'content': response_content,
                'handled_by': self.name,
                'timestamp': self._get_current_timestamp(),
                'success': True,
                'error': None
            }
            
        except Exception as e:
            self.logger.error(f"[InteractiveSecurityCheckAgent] Error in respond: {e}")
            return {
                'response_id': f"security_error_{self._get_current_timestamp()}",
                'content': f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø§Ù…Ù†ÛŒØª Ø°Ù‡Ù†ÛŒ: {str(e)}",
                'handled_by': self.name,
                'timestamp': self._get_current_timestamp(),
                'success': False,
                'error': str(e)
            }

    def _analyze_security_threats(self, message: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze text for cognitive/emotional security threats."""
        try:
            # First try pattern-based analysis
            pattern_result = self._pattern_based_threat_detection(message)
            
            # If OpenAI is available and pattern confidence is low, use GPT analysis
            if self.openai_client and pattern_result['confidence'] < 0.7:
                try:
                    gpt_result = self._gpt_threat_analysis(message, context)
                    # Combine pattern and GPT results
                    return self._combine_analysis_results(pattern_result, gpt_result)
                except Exception as e:
                    self.logger.warning(f"[InteractiveSecurityCheckAgent] GPT analysis failed: {e}")
                    return pattern_result
            
            return pattern_result
            
        except Exception as e:
            self.logger.error(f"[InteractiveSecurityCheckAgent] Error in threat analysis: {e}")
            return {
                'threat_type': ThreatType.NONE,
                'alert_level': AlertLevel.GREEN,
                'risk_score': 0.0,
                'recommendation': 'ØªØ­Ù„ÛŒÙ„ Ø§Ù…Ù†ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯',
                'confidence': 0.0,
                'analysis_data': {'error': str(e)}
            }

    def _pattern_based_threat_detection(self, message: str) -> Dict[str, Any]:
        """Detect threats using pattern matching."""
        message_lower = message.lower()
        detected_threats = []
        total_score = 0.0
        
        for threat_type, patterns in self.threat_patterns.items():
            threat_score = 0.0
            matches = []
            
            # Check keywords
            for keyword in patterns['keywords']:
                if keyword in message_lower:
                    threat_score += 0.3
                    matches.append(f"keyword: {keyword}")
            
            # Check phrases
            for phrase in patterns['phrases']:
                if phrase in message_lower:
                    threat_score += 0.5
                    matches.append(f"phrase: {phrase}")
            
            if threat_score > 0:
                detected_threats.append({
                    'type': threat_type,
                    'score': min(threat_score, 1.0),
                    'matches': matches,
                    'recommendation': patterns['recommendation']
                })
                total_score += threat_score
        
        # Determine primary threat
        if detected_threats:
            primary_threat = max(detected_threats, key=lambda x: x['score'])
            risk_score = min(total_score / 2, 1.0)  # Normalize
            
            # Determine alert level
            if risk_score >= 0.7:
                alert_level = AlertLevel.RED
            elif risk_score >= 0.4:
                alert_level = AlertLevel.YELLOW
            else:
                alert_level = AlertLevel.GREEN
                
            return {
                'threat_type': primary_threat['type'],
                'alert_level': alert_level,
                'risk_score': risk_score,
                'recommendation': primary_threat['recommendation'],
                'confidence': min(primary_threat['score'], 0.8),
                'analysis_data': {
                    'detected_threats': detected_threats,
                    'analysis_method': 'pattern_based'
                }
            }
        
        # No threats detected
        return {
            'threat_type': ThreatType.NONE,
            'alert_level': AlertLevel.GREEN,
            'risk_score': 0.0,
            'recommendation': 'âœ… ÙˆØ¶Ø¹ÛŒØª Ø°Ù‡Ù†ÛŒ Ø´Ù…Ø§ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯',
            'confidence': 0.6,
            'analysis_data': {'analysis_method': 'pattern_based', 'threats_found': 0}
        }

    def _gpt_threat_analysis(self, message: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Use OpenAI GPT for advanced threat analysis."""
        try:
            system_prompt = """ØªÙˆ ÛŒÚ© Ù…ØªØ®ØµØµ Ø§Ù…Ù†ÛŒØª Ø°Ù‡Ù†ÛŒ Ùˆ Ø±ÙˆØ§Ù†â€ŒØ´Ù†Ø§Ø³ Ù‡Ø³ØªÛŒ. Ù…ØªÙ† Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù† Ùˆ ØªÙ‡Ø¯ÛŒØ¯Ø§Øª Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ù„Ø§Ù…Øª Ø°Ù‡Ù†ÛŒ/Ø¹Ø§Ø·ÙÛŒ Ø§Ùˆ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†.

Ø§Ù†ÙˆØ§Ø¹ ØªÙ‡Ø¯ÛŒØ¯Ø§Øª:
- burnout: ÙØ±Ø³ÙˆØ¯Ú¯ÛŒ Ùˆ Ø®Ø³ØªÚ¯ÛŒ
- emotional_overload: Ø¨Ø§Ø± Ø¹Ø§Ø·ÙÛŒ Ø²ÛŒØ§Ø¯
- impulsivity: ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø¹Ø¬ÙˆÙ„Ø§Ù†Ù‡
- cognitive_fatigue: Ø®Ø³ØªÚ¯ÛŒ Ø°Ù‡Ù†ÛŒ
- stress_overload: Ø§Ø³ØªØ±Ø³ Ù…ÙØ±Ø·
- decision_paralysis: Ø¹Ø¯Ù… ØªÙˆØ§Ù†Ø§ÛŒÛŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ
- anxiety_spiral: Ù…Ø§Ø±Ù¾ÛŒÚ† Ø§Ø¶Ø·Ø±Ø§Ø¨
- none: Ø¨Ø¯ÙˆÙ† ØªÙ‡Ø¯ÛŒØ¯

Ø³Ø·ÙˆØ­ Ù‡Ø´Ø¯Ø§Ø±:
- green: Ø§Ù…Ù†
- yellow: Ø§Ø­ØªÛŒØ§Ø·
- red: Ø®Ø·Ø±

Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¯Ø± ÙØ±Ù…Øª JSON Ø§Ø±Ø§Ø¦Ù‡ Ú©Ù†:
{
  "threat_type": "Ù†ÙˆØ¹ ØªÙ‡Ø¯ÛŒØ¯",
  "alert_level": "Ø³Ø·Ø­ Ù‡Ø´Ø¯Ø§Ø±",
  "risk_score": Ø§Ù…ØªÛŒØ§Ø² Ø®Ø·Ø± (0.0-1.0),
  "recommendation": "ØªÙˆØµÛŒÙ‡ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ",
  "confidence": Ø§Ø·Ù…ÛŒÙ†Ø§Ù† (0.0-1.0)
}"""

            response = self.openai_client.chat.completions.create(
                model="gpt-4o",  # the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ØªØ­Ù„ÛŒÙ„ Ø§Ù…Ù†ÛŒØª Ø°Ù‡Ù†ÛŒ: {message}"}
                ],
                response_format={"type": "json_object"},
                max_tokens=500,
                temperature=0.3
            )
            
            result = json.loads(response.choices[0].message.content)
            
            return {
                'threat_type': ThreatType(result.get('threat_type', 'none')),
                'alert_level': AlertLevel(result.get('alert_level', 'green')),
                'risk_score': float(result.get('risk_score', 0.0)),
                'recommendation': result.get('recommendation', 'ØªØ­Ù„ÛŒÙ„ Ø§Ù…Ù†ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯'),
                'confidence': float(result.get('confidence', 0.5)),
                'analysis_data': {
                    'analysis_method': 'gpt_powered',
                    'gpt_response': result
                }
            }
            
        except Exception as e:
            self.logger.error(f"[InteractiveSecurityCheckAgent] GPT analysis failed: {e}")
            raise e

    def _combine_analysis_results(self, pattern_result: Dict, gpt_result: Dict) -> Dict[str, Any]:
        """Combine pattern-based and GPT analysis results."""
        # Use GPT result if it has higher confidence, otherwise combine
        if gpt_result['confidence'] > pattern_result['confidence']:
            return {
                **gpt_result,
                'analysis_data': {
                    'analysis_method': 'hybrid',
                    'pattern_result': pattern_result['analysis_data'],
                    'gpt_result': gpt_result['analysis_data']
                }
            }
        else:
            # Use pattern result but enhance with GPT insights
            return {
                **pattern_result,
                'recommendation': gpt_result.get('recommendation', pattern_result['recommendation']),
                'analysis_data': {
                    'analysis_method': 'hybrid',
                    'primary': 'pattern_based',
                    'pattern_result': pattern_result['analysis_data'],
                    'gpt_result': gpt_result['analysis_data']
                }
            }

    def _save_security_check(self, input_text: str, threat_type: ThreatType, alert_level: AlertLevel,
                           risk_score: float, recommendation: str, analysis_data: Dict[str, Any]) -> str:
        """Save security check analysis to database."""
        try:
            db = self.SessionLocal()
            
            security_check = SecurityCheck(
                input_text=input_text,
                detected_threat_type=threat_type,
                alert_level=alert_level,
                risk_score=risk_score,
                recommendation=recommendation,
                analysis_data=json.dumps(analysis_data, ensure_ascii=False)
            )
            
            db.add(security_check)
            db.commit()
            db.refresh(security_check)
            
            security_check_id = str(security_check.id)
            db.close()
            
            self.logger.info(f"[InteractiveSecurityCheckAgent] Security check saved with ID: {security_check_id}")
            return security_check_id
            
        except Exception as e:
            self.logger.error(f"[InteractiveSecurityCheckAgent] Error saving security check: {e}")
            return "error"

    def _format_security_response(self, analysis_result: Dict[str, Any], security_check_id: str) -> str:
        """Format security analysis response for display."""
        threat_type = analysis_result['threat_type']
        alert_level = analysis_result['alert_level']
        risk_score = analysis_result['risk_score']
        recommendation = analysis_result['recommendation']
        confidence = analysis_result['confidence']
        
        # Get emoji for alert level
        alert_emoji = {
            AlertLevel.GREEN: 'ðŸŸ¢',
            AlertLevel.YELLOW: 'ðŸŸ¡',
            AlertLevel.RED: 'ðŸ”´'
        }
        
        # Get threat type in Persian
        threat_persian = {
            ThreatType.BURNOUT: 'ÙØ±Ø³ÙˆØ¯Ú¯ÛŒ',
            ThreatType.EMOTIONAL_OVERLOAD: 'Ø¨Ø§Ø± Ø¹Ø§Ø·ÙÛŒ Ø²ÛŒØ§Ø¯',
            ThreatType.IMPULSIVITY: 'Ø¹Ø¬Ù„Ù‡ Ùˆ ØªÚ©Ø§Ù†Ø´Ú¯Ø±ÛŒ',
            ThreatType.COGNITIVE_FATIGUE: 'Ø®Ø³ØªÚ¯ÛŒ Ø°Ù‡Ù†ÛŒ',
            ThreatType.STRESS_OVERLOAD: 'Ø§Ø³ØªØ±Ø³ Ù…ÙØ±Ø·',
            ThreatType.DECISION_PARALYSIS: 'Ø¹Ø¯Ù… ØªÙˆØ§Ù†Ø§ÛŒÛŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ',
            ThreatType.ANXIETY_SPIRAL: 'Ù…Ø§Ø±Ù¾ÛŒÚ† Ø§Ø¶Ø·Ø±Ø§Ø¨',
            ThreatType.NONE: 'ØªÙ‡Ø¯ÛŒØ¯ Ø®Ø§ØµÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯'
        }
        
        response = f"""ðŸ›¡ï¸ **Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØª Ø°Ù‡Ù†ÛŒ:**

```json
{{
  "threat_type": "{threat_type.value}",
  "alert_level": "{alert_level.value}",
  "risk_score": {risk_score:.1f},
  "recommendation": "{recommendation}"
}}
```

**ðŸ“Š Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„:**
â€¢ {alert_emoji[alert_level]} **Ø³Ø·Ø­ Ù‡Ø´Ø¯Ø§Ø±:** {alert_level.value}
â€¢ ðŸ” **Ù†ÙˆØ¹ ØªÙ‡Ø¯ÛŒØ¯:** {threat_persian[threat_type]}
â€¢ âš¡ **Ø§Ù…ØªÛŒØ§Ø² Ø®Ø·Ø±:** {'â–ˆ' * int(risk_score * 5)}{'â–‘' * (5 - int(risk_score * 5))} ({risk_score * 100:.1f}%)
â€¢ ðŸ“ˆ **Ø§Ø·Ù…ÛŒÙ†Ø§Ù†:** {'â–ˆ' * int(confidence * 5)}{'â–‘' * (5 - int(confidence * 5))} ({confidence * 100:.1f}%)

**ðŸŽ¯ ØªÙˆØµÛŒÙ‡ Ø§Ù…Ù†ÛŒØªÛŒ:**
{recommendation}

ðŸ›¡ï¸ **Ù†Ú©ØªÙ‡:** Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØª Ø°Ù‡Ù†ÛŒ Ùˆ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø®ØªÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª."""

        return response

    def _get_current_timestamp(self) -> str:
        """Get current timestamp in ISO format."""
        return datetime.now().isoformat()

    def get_capabilities(self) -> list:
        """Get list of agent capabilities."""
        return [
            "ØªØ­Ù„ÛŒÙ„ Ø§Ù…Ù†ÛŒØª Ø°Ù‡Ù†ÛŒ",
            "Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ØªÙ‡Ø¯ÛŒØ¯Ø§Øª Ø´Ù†Ø§Ø®ØªÛŒ",
            "Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø®Ø·Ø± Ø¹Ø§Ø·ÙÛŒ",
            "ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ø´Ø®ØµÛŒ",
            "Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ø³Ù„Ø§Ù…Øª Ø±ÙˆØ§Ù†",
            "Ù‡Ø´Ø¯Ø§Ø± Ø§Ù…Ù†ÛŒØª Ø°Ù‡Ù†ÛŒ",
            "Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø§Ù…Ù†"
        ]

    def get_database_stats(self) -> Dict[str, Any]:
        """Get database statistics for security checks."""
        try:
            db = self.SessionLocal()
            
            total_checks = db.query(SecurityCheck).count()
            
            # Count by alert level
            green_count = db.query(SecurityCheck).filter(SecurityCheck.alert_level == AlertLevel.GREEN).count()
            yellow_count = db.query(SecurityCheck).filter(SecurityCheck.alert_level == AlertLevel.YELLOW).count()
            red_count = db.query(SecurityCheck).filter(SecurityCheck.alert_level == AlertLevel.RED).count()
            
            # Count by threat type
            threat_counts = {}
            for threat_type in ThreatType:
                count = db.query(SecurityCheck).filter(SecurityCheck.detected_threat_type == threat_type).count()
                threat_counts[threat_type.value] = count
            
            db.close()
            
            return {
                'total_security_checks': total_checks,
                'alert_levels': {
                    'green': green_count,
                    'yellow': yellow_count,
                    'red': red_count
                },
                'threat_types': threat_counts,
                'timestamp': self._get_current_timestamp()
            }
            
        except Exception as e:
            self.logger.error(f"[InteractiveSecurityCheckAgent] Error getting database stats: {e}")
            return {'error': str(e)}

    def list_recent_security_checks(self, limit: int = 10) -> Dict[str, Any]:
        """Get recent security check analyses."""
        try:
            db = self.SessionLocal()
            
            security_checks = db.query(SecurityCheck).order_by(
                SecurityCheck.created_at.desc()
            ).limit(limit).all()
            
            checks_data = []
            for check in security_checks:
                checks_data.append({
                    'id': str(check.id),
                    'input_text': check.input_text,
                    'detected_threat_type': check.detected_threat_type.value,
                    'alert_level': check.alert_level.value,
                    'risk_score': check.risk_score,
                    'recommendation': check.recommendation,
                    'created_at': check.created_at.isoformat()
                })
            
            db.close()
            
            return {
                'security_checks': checks_data,
                'count': len(checks_data),
                'timestamp': self._get_current_timestamp()
            }
            
        except Exception as e:
            self.logger.error(f"[InteractiveSecurityCheckAgent] Error listing security checks: {e}")
            return {'error': str(e), 'security_checks': [], 'count': 0}