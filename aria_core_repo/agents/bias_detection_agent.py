"""
BiasDetectionAgent - Cognitive bias detection and reflection agent.
"""

import json
import logging
import os
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any

from openai import OpenAI
from sqlalchemy import create_engine, Column, String, DateTime, Float, Text, ARRAY
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

from agents.base_agent import BaseAgent

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Database setup
DATABASE_URL = os.environ.get('DATABASE_URL')
engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

class BiasLog(Base):
    __tablename__ = 'bias_logs'
    
    id = Column(String, primary_key=True)
    timestamp = Column(DateTime, default=datetime.utcnow)
    input_text = Column(Text)
    bias_type = Column(Text)
    severity_score = Column(Float)
    suggestion = Column(Text)

# Create tables
Base.metadata.create_all(bind=engine)

class BiasDetectionAgent(BaseAgent):
    """
    Advanced cognitive bias detection agent with GPT-4o integration.
    Detects and analyzes cognitive biases in user decisions and beliefs.
    """
    
    def __init__(self):
        super().__init__("BiasDetectionAgent")
        self.description = "Cognitive bias detection and reflection agent"
        
        # Initialize OpenAI client
        self.openai_client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))
        
        # Supported bias types with patterns
        self.bias_patterns = {
            'confirmation_bias': {
                'keywords': ['confirms', 'belief', 'ignore', 'negative', 'support', 'view', 'proves', 'right', 'expected', 'only read', 'selective'],
                'phrases': ['confirms my belief', 'ignore negative information', 'support my view', 'proves I\'m right', 'as I expected', 'only read things that', 'selective reading'],
                'persian_name': 'Ø³ÙˆÚ¯ÛŒØ±ÛŒ ØªØ£ÛŒÛŒØ¯',
                'description': 'ØªÙ…Ø§ÛŒÙ„ Ø¨Ù‡ Ø¬Ø³ØªØ¬ÙˆØŒ ØªÙØ³ÛŒØ± Ùˆ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ú©Ù‡ Ø¨Ø§ÙˆØ±Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø±Ø§ ØªØ£ÛŒÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯'
            },
            'availability_bias': {
                'keywords': ['recently', 'heard', 'saw', 'news', 'remember', 'recall', 'comes to mind', 'just', 'lately'],
                'phrases': ['I recently heard', 'I saw on news', 'comes to mind', 'I remember', 'just heard about', 'recent example'],
                'persian_name': 'Ø³ÙˆÚ¯ÛŒØ±ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ',
                'description': 'ØªÙ…Ø§ÛŒÙ„ Ø¨Ù‡ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ù‡ Ø±Ø§Ø­ØªÛŒ Ø¨Ù‡ ÛŒØ§Ø¯ Ù…ÛŒâ€ŒØ¢ÛŒÙ†Ø¯'
            },
            'overconfidence': {
                'keywords': ['certain', 'definitely', 'absolutely', 'sure', 'doubt', 'guaranteed', 'predict', 'always', 'never', 'perfect'],
                'phrases': ['absolutely certain', 'definitely will', 'no doubt', 'I know for sure', 'guaranteed', 'I can predict', 'always right', 'never wrong'],
                'persian_name': 'Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯',
                'description': 'Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ø¨Ù‡ Ù‚Ø¶Ø§ÙˆØªâ€ŒÙ‡Ø§ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Ø´Ø®ØµÛŒ'
            },
            'anchoring': {
                'keywords': ['first', 'initial', 'starting', 'original', 'baseline', 'anchor', 'impression', 'beginning'],
                'phrases': ['first impression', 'initial price', 'starting point', 'based on first', 'original estimate', 'initial thought'],
                'persian_name': 'Ø³ÙˆÚ¯ÛŒØ±ÛŒ Ù„Ù†Ú¯Ø±',
                'description': 'ØªØ£Ø«ÛŒØ± Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø¯Ø± ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ'
            },
            'sunk_cost_fallacy': {
                'keywords': ['already', 'invested', 'spent', 'waste', 'continue', 'paid', 'money', 'time', 'much'],
                'phrases': ['already invested', 'already spent', 'can\'t waste', 'have to continue', 'already paid', 'invested too much', 'waste money'],
                'persian_name': 'Ù…ØºØ§Ù„Ø·Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ ÙØ±ÙˆØ±ÙØªÙ‡',
                'description': 'Ø§Ø¯Ø§Ù…Ù‡ ÛŒÚ© Ø±ÙØªØ§Ø± ÛŒØ§ ØªÙ„Ø§Ø´ ØµØ±ÙØ§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù‚Ø¨Ù„ÛŒ'
            },
            'negativity_bias': {
                'keywords': ['everything', 'always', 'never', 'worst', 'bad', 'terrible', 'disaster', 'hopeless', 'doomed'],
                'phrases': ['everything is bad', 'always fails', 'never works', 'worst case', 'terrible', 'hopeless', 'doomed'],
                'persian_name': 'Ø³ÙˆÚ¯ÛŒØ±ÛŒ Ù…Ù†ÙÛŒ',
                'description': 'ØªÙ…Ø§ÛŒÙ„ Ø¨Ù‡ ØªÙˆØ¬Ù‡ Ø¨ÛŒØ´ØªØ± Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù†ÙÛŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù…Ø«Ø¨Øª'
            },
            'framing_effect': {
                'keywords': ['depends', 'perspective', 'way', 'look', 'angle', 'side', 'frame', 'reframe', 'half'],
                'phrases': ['depends how you', 'matter of perspective', 'way to look at it', 'different angle', 'positive side', 'negative side', 'glass half'],
                'persian_name': 'Ø§Ø«Ø± Ù‚Ø§Ø¨â€ŒØ¨Ù†Ø¯ÛŒ',
                'description': 'ØªØ£Ø«ÛŒØ± Ø´ÛŒÙˆÙ‡ Ø§Ø±Ø§Ø¦Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø± ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ'
            }
        }
        
        logger.info(f"[{self.name}] Bias detection patterns and analysis framework initialized")
        
        # Initialize database
        self._init_database()
        
        logger.info(f"[{self.name}] OpenAI GPT integration ready for bias analysis")
        logger.info(f"[{self.name}] Initialized with PostgreSQL database integration for bias tracking")
    
    def _init_database(self):
        """Initialize database tables for bias logging"""
        try:
            # Create tables if they don't exist
            Base.metadata.create_all(bind=engine)
            logger.info(f"[{self.name}] Bias logs table ready")
        except Exception as e:
            logger.error(f"[{self.name}] Database initialization failed: {e}")
    
    def _detect_bias_patterns(self, text: str) -> Dict[str, Any]:
        """
        Detect cognitive biases using pattern matching.
        
        Args:
            text (str): Input text to analyze
            
        Returns:
            Dict: Detected biases with scores
        """
        detected_biases = []
        severity_scores = []
        
        text_lower = text.lower()
        
        for bias_type, pattern_info in self.bias_patterns.items():
            score = 0.0
            matches = 0
            
            # Check keywords
            for keyword in pattern_info['keywords']:
                if keyword.lower() in text_lower:
                    score += 0.1
                    matches += 1
            
            # Check phrases (higher weight)
            for phrase in pattern_info['phrases']:
                if phrase.lower() in text_lower:
                    score += 0.3
                    matches += 1
            
            # Calculate final score
            if matches > 0:
                final_score = min(score, 1.0)
                if final_score >= 0.3:  # Minimum threshold
                    detected_biases.append(bias_type)
                    severity_scores.append(final_score)
        
        return {
            'detected_biases': detected_biases,
            'severity_scores': severity_scores,
            'method': 'pattern_matching'
        }
    
    def _analyze_bias_with_gpt(self, text: str) -> Dict[str, Any]:
        """
        Analyze cognitive biases using OpenAI GPT-4o.
        
        Args:
            text (str): Input text to analyze
            
        Returns:
            Dict: GPT analysis results
        """
        try:
            # the newest OpenAI model is "gpt-4o" which was released May 13, 2024.
            # do not change this unless explicitly requested by the user
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": """Ø´Ù…Ø§ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± ØªØ®ØµØµÛŒ Ø³ÙˆÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø®ØªÛŒ Ù‡Ø³ØªÛŒØ¯. Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯ Ùˆ Ø³ÙˆÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯.

Ø³ÙˆÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªØ´Ø®ÛŒØµ:
- confirmation_bias: Ø³ÙˆÚ¯ÛŒØ±ÛŒ ØªØ£ÛŒÛŒØ¯
- availability_bias: Ø³ÙˆÚ¯ÛŒØ±ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ  
- overconfidence: Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯
- anchoring: Ø³ÙˆÚ¯ÛŒØ±ÛŒ Ù„Ù†Ú¯Ø±
- sunk_cost_fallacy: Ù…ØºØ§Ù„Ø·Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ ÙØ±ÙˆØ±ÙØªÙ‡
- negativity_bias: Ø³ÙˆÚ¯ÛŒØ±ÛŒ Ù…Ù†ÙÛŒ
- framing_effect: Ø§Ø«Ø± Ù‚Ø§Ø¨â€ŒØ¨Ù†Ø¯ÛŒ

Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¯Ø± Ù‚Ø§Ù„Ø¨ JSON Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯:
{
  "bias_detected": true/false,
  "bias_types": ["bias1", "bias2", ...],
  "severity_score": 0.0-1.0,
  "confidence": 0.0-1.0,
  "reasoning": "Ø¯Ù„ÛŒÙ„ ØªØ´Ø®ÛŒØµ",
  "suggestion": "Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ ØªØ£Ù…Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±"
}"""
                    },
                    {
                        "role": "user",
                        "content": f"Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„: {text}"
                    }
                ],
                response_format={"type": "json_object"},
                max_tokens=800,
                temperature=0.3
            )
            
            result = json.loads(response.choices[0].message.content)
            result['method'] = 'gpt_analysis'
            return result
            
        except Exception as e:
            logger.error(f"[{self.name}] GPT analysis failed: {e}")
            return None
    
    def _generate_reflection_suggestion(self, bias_types: List[str], severity: float) -> str:
        """
        Generate a reflective suggestion based on detected biases.
        
        Args:
            bias_types (List[str]): List of detected bias types
            severity (float): Severity score
            
        Returns:
            str: Reflection suggestion
        """
        if not bias_types:
            return "ØªØ­Ù„ÛŒÙ„ Ø´Ù…Ø§ Ù…ØªØ¹Ø§Ø¯Ù„ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯. Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ù‡ÛŒØ¯!"
        
        primary_bias = bias_types[0]
        bias_info = self.bias_patterns.get(primary_bias, {})
        bias_name = bias_info.get('persian_name', primary_bias)
        
        suggestions = {
            'confirmation_bias': "Ø¢ÛŒØ§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø´ÙˆØ§Ù‡Ø¯ Ù…Ø®Ø§Ù„Ù Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯ØŸ Ø³Ø¹ÛŒ Ú©Ù†ÛŒØ¯ Ø¯ÛŒØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.",
            'availability_bias': "Ø¢ÛŒØ§ Ø§ÛŒÙ† ØªØµÙ…ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¬Ø±Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ± Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù‡ØŸ Ø³Ø¹ÛŒ Ú©Ù†ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒâ€ŒØªØ± Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±ÛŒØ¯.",
            'overconfidence': "Ø¢ÛŒØ§ Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø´ØªØ¨Ø§Ù‡ Ø¨ÙˆØ¯Ù† Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡â€ŒØ§ÛŒØ¯ØŸ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú©Ù…ÛŒ Ù…Ø­ØªØ§Ø·â€ŒØªØ± Ø¹Ù…Ù„ Ú©Ù†ÛŒØ¯.",
            'anchoring': "Ø¢ÛŒØ§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø± ØªØµÙ…ÛŒÙ… Ø´Ù…Ø§ ØªØ£Ø«ÛŒØ± Ú¯Ø°Ø§Ø´ØªÙ‡ØŸ Ø³Ø¹ÛŒ Ú©Ù†ÛŒØ¯ Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.",
            'sunk_cost_fallacy': "Ø¢ÛŒØ§ ÙÙ‚Ø· Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù‚Ø¨Ù„ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒØ¯ØŸ Ú¯Ø§Ù‡ÛŒ ØªØ±Ú© Ú©Ø±Ø¯Ù† Ø¨Ù‡ØªØ±ÛŒÙ† Ø±Ø§Ù‡ Ø§Ø³Øª.",
            'negativity_bias': "Ø¢ÛŒØ§ Ø±ÙˆÛŒ Ø¬Ù†Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù†ÙÛŒ ØªÙ…Ø±Ú©Ø² Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯ØŸ Ø³Ø¹ÛŒ Ú©Ù†ÛŒØ¯ Ù†Ú©Ø§Øª Ù…Ø«Ø¨Øª Ø±Ø§ Ù†ÛŒØ² Ø¨Ø¨ÛŒÙ†ÛŒØ¯.",
            'framing_effect': "Ø¢ÛŒØ§ Ø´ÛŒÙˆÙ‡ Ø§Ø±Ø§Ø¦Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø± Ù†Ø¸Ø± Ø´Ù…Ø§ ØªØ£Ø«ÛŒØ± Ú¯Ø°Ø§Ø´ØªÙ‡ØŸ Ø³Ø¹ÛŒ Ú©Ù†ÛŒØ¯ Ø§Ø² Ø²ÙˆØ§ÛŒØ§ÛŒ Ù…Ø®ØªÙ„Ù Ù†Ú¯Ø§Ù‡ Ú©Ù†ÛŒØ¯."
        }
        
        base_suggestion = suggestions.get(primary_bias, "Ø¯Ø± Ù†Ø¸Ø± Ú¯ÛŒØ±ÛŒ Ø¯ÛŒØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù…ÙÛŒØ¯ Ø¨Ø§Ø´Ø¯.")
        
        if severity >= 0.7:
            return f"âš ï¸ **Ø³ÙˆÚ¯ÛŒØ±ÛŒ {bias_name}** Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ ØªØ£Ø«ÛŒØ± Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¯Ø§Ø±Ø¯. {base_suggestion}"
        elif severity >= 0.5:
            return f"ğŸ“ **Ø³ÙˆÚ¯ÛŒØ±ÛŒ {bias_name}** Ù…Ù…Ú©Ù† Ø§Ø³Øª ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯. {base_suggestion}"
        else:
            return f"â„¹ï¸ **Ø³ÙˆÚ¯ÛŒØ±ÛŒ {bias_name}** Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø®ÙÛŒÙÛŒ Ø¯Ø§Ø±Ø¯. {base_suggestion}"
    
    def analyze_bias(self, text: str) -> Dict[str, Any]:
        """
        Analyze text for cognitive biases using hybrid approach.
        
        Args:
            text (str): Input text to analyze
            
        Returns:
            Dict: Bias analysis results
        """
        self.remember(f"Bias analysis for: {text[:50]}...")
        
        # Start with pattern-based analysis
        pattern_result = self._detect_bias_patterns(text)
        
        # Try GPT analysis as primary method
        gpt_result = self._analyze_bias_with_gpt(text)
        
        # Combine results
        if gpt_result and gpt_result.get('bias_detected'):
            # Use GPT results as primary
            bias_types = gpt_result.get('bias_types', [])
            severity = gpt_result.get('severity_score', 0.0)
            confidence = gpt_result.get('confidence', 0.0)
            method = 'gpt_analysis'
            reasoning = gpt_result.get('reasoning', '')
            
            # Convert bias types to Persian names
            persian_bias_names = []
            for bias in bias_types:
                bias_info = self.bias_patterns.get(bias, {})
                persian_name = bias_info.get('persian_name', bias)
                persian_bias_names.append(persian_name)
            
        elif pattern_result['detected_biases']:
            # Fallback to pattern matching
            bias_types = pattern_result['detected_biases']
            severity = max(pattern_result['severity_scores']) if pattern_result['severity_scores'] else 0.0
            confidence = 0.6  # Pattern matching confidence
            method = 'pattern_matching'
            reasoning = f"ØªØ´Ø®ÛŒØµ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„Ù…Ø§Øª Ùˆ Ø¹Ø¨Ø§Ø±Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø³ÙˆÚ¯ÛŒØ±ÛŒ"
            
            # Convert bias types to Persian names
            persian_bias_names = []
            for bias in bias_types:
                bias_info = self.bias_patterns.get(bias, {})
                persian_name = bias_info.get('persian_name', bias)
                persian_bias_names.append(persian_name)
                
        else:
            # No bias detected
            bias_types = []
            persian_bias_names = []
            severity = 0.0
            confidence = 0.8
            method = 'no_bias_detected'
            reasoning = "Ù‡ÛŒÚ† Ø³ÙˆÚ¯ÛŒØ±ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯"
        
        # Generate reflection suggestion
        suggestion = self._generate_reflection_suggestion(bias_types, severity)
        
        # Save to database
        bias_log_id = str(uuid.uuid4())
        # Convert list to comma-separated string for database storage
        bias_types_str = ', '.join(bias_types) if bias_types else ''
        
        # Only save if there are actual biases detected or if severity > 0
        if bias_types_str or severity > 0:
            self._save_bias_log(bias_log_id, text, bias_types_str, severity, suggestion)
        
        self.remember(f"Bias analysis completed: {len(bias_types)} biases detected with {severity:.2f} severity")
        
        return {
            'bias_detected': len(bias_types) > 0,
            'bias_type': persian_bias_names,
            'severity_score': severity,
            'confidence': confidence,
            'suggestion': suggestion,
            'method': method,
            'reasoning': reasoning,
            'log_id': bias_log_id
        }
    
    def _save_bias_log(self, log_id: str, input_text: str, bias_types_str: str, severity: float, suggestion: str):
        """Save bias analysis to database"""
        try:
            session = SessionLocal()
            
            bias_log = BiasLog(
                id=log_id,
                timestamp=datetime.utcnow(),
                input_text=input_text,
                bias_type=bias_types_str,
                severity_score=severity,
                suggestion=suggestion
            )
            
            session.add(bias_log)
            session.commit()
            session.close()
            
            logger.info(f"[{self.name}] Bias log saved with ID: {log_id}")
            
        except Exception as e:
            logger.error(f"[{self.name}] Failed to save bias log: {e}")
    
    def get_bias_logs(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Get recent bias analysis logs.
        
        Args:
            limit (int): Number of logs to retrieve
            
        Returns:
            List[Dict]: Recent bias logs
        """
        try:
            session = SessionLocal()
            
            logs = session.query(BiasLog).order_by(BiasLog.timestamp.desc()).limit(limit).all()
            
            result = []
            for log in logs:
                # Convert comma-separated string back to list for display
                bias_types_list = log.bias_type.split(', ') if log.bias_type and log.bias_type != 'None' else []
                result.append({
                    'id': log.id,
                    'timestamp': log.timestamp.isoformat(),
                    'input_text': log.input_text,
                    'bias_type': bias_types_list,
                    'severity_score': log.severity_score,
                    'suggestion': log.suggestion
                })
            
            session.close()
            
            return result
            
        except Exception as e:
            logger.error(f"[{self.name}] Failed to retrieve bias logs: {e}")
            return []
    
    def respond(self, message: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Process message and analyze for cognitive biases.
        
        Args:
            message (str): The message to analyze
            context (Dict): Optional context information
            
        Returns:
            Dict: Response containing bias analysis
        """
        try:
            # Analyze for cognitive biases
            analysis = self.analyze_bias(message)
            
            # Format response
            if analysis['bias_detected']:
                bias_names = ', '.join(analysis['bias_type'])
                severity_bar = 'â–ˆ' * int(analysis['severity_score'] * 5) + 'â–‘' * (5 - int(analysis['severity_score'] * 5))
                
                response = f"""ğŸ§  **ØªØ­Ù„ÛŒÙ„ Ø³ÙˆÚ¯ÛŒØ±ÛŒ Ø´Ù†Ø§Ø®ØªÛŒ:**

```json
{json.dumps(analysis, ensure_ascii=False, indent=2)}
```

**ğŸ” Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„:**
â€¢ ğŸ¯ **Ø³ÙˆÚ¯ÛŒØ±ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:** {bias_names}
â€¢ ğŸ“Š **Ø´Ø¯Øª:** {severity_bar} ({analysis['severity_score']:.1%})
â€¢ ğŸ¤” **Ø§Ø·Ù…ÛŒÙ†Ø§Ù†:** {analysis['confidence']:.1%}
â€¢ ğŸ”¬ **Ø±ÙˆØ´ ØªØ´Ø®ÛŒØµ:** {analysis['method']}

**ğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ ØªØ£Ù…Ù„ÛŒ:**
{analysis['suggestion']}

**ğŸ“‹ Ø´Ù†Ø§Ø³Ù‡ Ù„Ø§Ú¯:** {analysis['log_id']}"""
                
            else:
                response = f"""ğŸ§  **ØªØ­Ù„ÛŒÙ„ Ø³ÙˆÚ¯ÛŒØ±ÛŒ Ø´Ù†Ø§Ø®ØªÛŒ:**

```json
{json.dumps(analysis, ensure_ascii=False, indent=2)}
```

**âœ… Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„:**
â€¢ ğŸ¯ **ÙˆØ¶Ø¹ÛŒØª:** Ù‡ÛŒÚ† Ø³ÙˆÚ¯ÛŒØ±ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯
â€¢ ğŸ¤” **Ø§Ø·Ù…ÛŒÙ†Ø§Ù†:** {analysis['confidence']:.1%}
â€¢ ğŸ’¡ **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯:** {analysis['suggestion']}

**ğŸ“‹ Ø´Ù†Ø§Ø³Ù‡ Ù„Ø§Ú¯:** {analysis['log_id']}"""
            
            return {
                'success': True,
                'analysis': analysis,
                'response': response
            }
            
        except Exception as e:
            logger.error(f"[{self.name}] Error in respond: {e}")
            return {
                'success': False,
                'error': str(e),
                'response': f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø³ÙˆÚ¯ÛŒØ±ÛŒ: {e}"
            }