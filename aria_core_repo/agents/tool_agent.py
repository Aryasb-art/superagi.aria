"""
Tool Agent for comprehensive task processing and analysis using OpenAI GPT API.
"""

import os
import json
import logging
from typing import Dict, Any, Optional, List, Tuple
from openai import OpenAI
from datetime import datetime
from textblob import TextBlob
from .base_agent import BaseAgent

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ToolAgent(BaseAgent):
    """
    Tool Agent that handles various text processing tasks with detailed logging.
    Uses OpenAI GPT API for task analysis and execution.
    """
    
    def __init__(self):
        super().__init__(
            name="ToolAgent",
            description="Comprehensive tool agent for task processing, analysis, and execution using OpenAI GPT"
        )
        
        # Initialize OpenAI client
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        
        self.openai_client = OpenAI(api_key=self.openai_api_key)
        
        # Keywords for routing messages to this agent
        self.keywords = [
            "ØªØ­Ù„ÛŒÙ„", "analysis", "Ø¢Ù†Ø§Ù„ÛŒØ²", "analyze",
            "Ù¾Ø±Ø¯Ø§Ø²Ø´", "process", "processing",
            "Ø§Ø³ØªØ®Ø±Ø§Ø¬", "extract", "extraction",
            "Ø§Ø¨Ø²Ø§Ø±", "tool", "tools", "ØªÙˆÙ„",
            "Ø¹Ù…Ù„Ú©Ø±Ø¯", "operation", "Ú©Ø§Ø±", "work",
            "Ø§Ù†Ø¬Ø§Ù…", "execute", "Ø§Ø¬Ø±Ø§", "run",
            "Ø§Ø­Ø³Ø§Ø³", "Ø§Ø­Ø³Ø§Ø³Ø§Øª", "sentiment", "emotion"
        ]
        
        # Task types mapping
        self.task_types = {
            "summary": ["Ø®Ù„Ø§ØµÙ‡", "Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ", "summary", "summarize"],
            "translation": ["ØªØ±Ø¬Ù…Ù‡", "translate", "translation", "ØªØ¨Ø¯ÛŒÙ„"],
            "extraction": ["Ø§Ø³ØªØ®Ø±Ø§Ø¬", "extract", "extraction", "Ø¨ÛŒØ±ÙˆÙ† Ú©Ø´ÛŒØ¯Ù†"],
            "analysis": ["ØªØ­Ù„ÛŒÙ„", "analyze", "analysis", "Ø¢Ù†Ø§Ù„ÛŒØ²"],
            "improvement": ["Ø¨Ù‡Ø¨ÙˆØ¯", "improve", "improvement", "ØªØµØ­ÛŒØ­", "correct"],
            "conversion": ["ØªØ¨Ø¯ÛŒÙ„", "convert", "conversion", "ØªØºÛŒÛŒØ±"],
            "generation": ["ØªÙˆÙ„ÛŒØ¯", "generate", "generation", "Ø§ÛŒØ¬Ø§Ø¯", "create"],
            "sentiment": ["Ø§Ø­Ø³Ø§Ø³", "Ø§Ø­Ø³Ø§Ø³Ø§Øª", "sentiment", "emotion", "ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³"]
        }
        
        logger.info(f"[{self.name}] Initialized with OpenAI GPT integration and task processing capabilities")
    
    def respond(self, message: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Process message and generate appropriate response using OpenAI GPT.
        
        Args:
            message (str): The message to respond to
            context (Dict): Optional context information
            
        Returns:
            Dict: Response containing the agent's reply
        """
        start_time = datetime.now()
        
        try:
            # Log the incoming message
            self.log(f"Processing task: {message[:100]}...")
            
            # Remember the user message
            self.remember(f"User: {message}")
            
            # Process the task
            task_result = self.process_task(message)
            
            # Create response
            response = {
                "response_id": f"tool_{hash(message + str(context)) % 100000}",
                "content": task_result["content"],
                "handled_by": self.name,
                "timestamp": self._get_current_timestamp(),
                "success": task_result["success"],
                "task_type": task_result["task_type"],
                "processing_time": task_result.get("processing_time", 0),
                "error": task_result.get("error")
            }
            
            # Remember the agent response
            self.remember(f"Agent: {task_result['content'][:100]}...")
            
            # Log completion
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            self.log(f"Task completed: {task_result['task_type']} in {processing_time:.2f}s - Success: {task_result['success']}")
            
            return response
            
        except Exception as e:
            error_message = f"Error processing task: {str(e)}"
            self.log(error_message, level="error")
            
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            return {
                "response_id": f"tool_error_{hash(message) % 100000}",
                "content": f"Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆØ¸ÛŒÙÙ‡ Ø´Ù…Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯: {str(e)}",
                "handled_by": self.name,
                "timestamp": self._get_current_timestamp(),
                "success": False,
                "processing_time": processing_time,
                "error": error_message
            }
    
    def process_task(self, message: str) -> Dict[str, Any]:
        """
        Process the task based on message content and return detailed results.
        
        Args:
            message (str): The input message containing the task
            
        Returns:
            Dict: Task processing results
        """
        start_time = datetime.now()
        
        try:
            # Determine task type
            task_type, confidence = self._analyze_task_type(message)
            
            self.log(f"Task type identified: {task_type} (confidence: {confidence:.2f})")
            
            # Extract content from message
            content = self._extract_task_content(message, task_type)
            
            # Execute the task based on type
            if task_type == "summary":
                result = self._execute_summary_task(content)
            elif task_type == "translation":
                result = self._execute_translation_task(content)
            elif task_type == "extraction":
                result = self._execute_extraction_task(content)
            elif task_type == "analysis":
                result = self._execute_analysis_task(content)
            elif task_type == "improvement":
                result = self._execute_improvement_task(content)
            elif task_type == "conversion":
                result = self._execute_conversion_task(content)
            elif task_type == "generation":
                result = self._execute_generation_task(content)
            elif task_type == "sentiment":
                result = self._execute_sentiment_task(content)
            else:
                result = self._execute_general_task(message)
            
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            return {
                "content": result,
                "success": True,
                "task_type": task_type,
                "confidence": confidence,
                "processing_time": processing_time,
                "error": None
            }
            
        except Exception as e:
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            self.log(f"Task processing failed: {str(e)}", level="error")
            
            return {
                "content": f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†Ø¬Ø§Ù… ÙˆØ¸ÛŒÙÙ‡: {str(e)}",
                "success": False,
                "task_type": "unknown",
                "confidence": 0.0,
                "processing_time": processing_time,
                "error": str(e)
            }
    
    def _analyze_task_type(self, message: str) -> Tuple[str, float]:
        """
        Analyze message to determine task type and confidence level.
        
        Args:
            message (str): Input message
            
        Returns:
            Tuple[str, float]: Task type and confidence score
        """
        message_lower = message.lower()
        
        # Check each task type for keyword matches
        best_match = "general"
        best_score = 0.0
        
        for task_type, keywords in self.task_types.items():
            score = 0.0
            for keyword in keywords:
                if keyword in message_lower:
                    score += 1.0
            
            # Normalize score by number of keywords
            normalized_score = score / len(keywords) if keywords else 0.0
            
            if normalized_score > best_score:
                best_score = normalized_score
                best_match = task_type
        
        return best_match, best_score
    
    def _extract_task_content(self, message: str, task_type: str) -> str:
        """
        Extract the main content for processing from the message.
        
        Args:
            message (str): Original message
            task_type (str): Identified task type
            
        Returns:
            str: Extracted content
        """
        # Remove task-specific command words
        content = message
        
        # Get keywords for the identified task type
        if task_type in self.task_types:
            for keyword in self.task_types[task_type]:
                content = content.replace(keyword, "").strip()
        
        # Remove common separators
        content = content.replace(":", "").replace("Ú©Ù†", "").strip()
        
        return content if content else message
    
    def _execute_summary_task(self, content: str) -> str:
        """Execute summarization task."""
        try:
            prompt = f"""
            Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø²ÛŒØ± Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø®Ù„Ø§ØµÙ‡ Ùˆ Ù…ÙÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ Ú©Ù†ÛŒØ¯:
            - Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø±Ø§ Ø­ÙØ¸ Ú©Ù†ÛŒØ¯
            - ÙˆØ§Ø¶Ø­ Ùˆ Ù…ÙÙ‡ÙˆÙ… Ø¨Ø§Ø´Ø¯
            - Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯
            
            Ù…ØªÙ†: {content}
            """
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",  # the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,
                temperature=0.7
            )
            
            result = response.choices[0].message.content
            return f"ğŸ“ **Ø®Ù„Ø§ØµÙ‡ Ù…ØªÙ†:**\n\n{result}"
            
        except Exception as e:
            return f"Ø®Ø·Ø§ Ø¯Ø± Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ: {str(e)}"
    
    def _execute_translation_task(self, content: str) -> str:
        """Execute translation task."""
        try:
            prompt = f"""
            Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø²ÛŒØ± Ø±Ø§ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†ÛŒØ¯:
            - Ø§Ú¯Ø± ÙØ§Ø±Ø³ÛŒ Ø§Ø³ØªØŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†ÛŒØ¯
            - Ø§Ú¯Ø± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³ØªØŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†ÛŒØ¯
            - Ø§Ú¯Ø± Ø²Ø¨Ø§Ù† Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ø³ØªØŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†ÛŒØ¯
            
            Ù…ØªÙ†: {content}
            """
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",  # the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
                messages=[{"role": "user", "content": prompt}],
                max_tokens=800,
                temperature=0.3
            )
            
            result = response.choices[0].message.content
            return f"ğŸŒ **ØªØ±Ø¬Ù…Ù‡:**\n\n{result}"
            
        except Exception as e:
            return f"Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ø¬Ù…Ù‡: {str(e)}"
    
    def _execute_extraction_task(self, content: str) -> str:
        """Execute information extraction task."""
        try:
            prompt = f"""
            Ù„Ø·ÙØ§Ù‹ Ø§Ø² Ù…ØªÙ† Ø²ÛŒØ± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù‡Ù… Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒØ¯:
            - Ù†Ø§Ù…â€ŒÙ‡Ø§ØŒ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ØŒ Ø§Ø¹Ø¯Ø§Ø¯
            - Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ùˆ Ù…ÙØ§Ù‡ÛŒÙ… Ø§ØµÙ„ÛŒ
            - Ø¨Ù‡ ØµÙˆØ±Øª ÙÙ‡Ø±Ø³Øª Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯
            
            Ù…ØªÙ†: {content}
            """
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",  # the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
                messages=[{"role": "user", "content": prompt}],
                max_tokens=600,
                temperature=0.5
            )
            
            result = response.choices[0].message.content
            return f"ğŸ” **Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:**\n\n{result}"
            
        except Exception as e:
            return f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª: {str(e)}"
    
    def _execute_analysis_task(self, content: str) -> str:
        """Execute analysis task."""
        try:
            prompt = f"""
            Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø²ÛŒØ± Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯:
            - Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ Ùˆ Ø²ÛŒØ±Ù…ÙˆØ¶ÙˆØ¹Ø§Øª
            - Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ùˆ Ø¶Ø¹Ù
            - Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª
            
            Ù…ØªÙ†: {content}
            """
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",  # the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
                messages=[{"role": "user", "content": prompt}],
                max_tokens=800,
                temperature=0.6
            )
            
            result = response.choices[0].message.content
            return f"ğŸ“Š **ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ†:**\n\n{result}"
            
        except Exception as e:
            return f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„: {str(e)}"
    
    def _execute_improvement_task(self, content: str) -> str:
        """Execute text improvement task."""
        try:
            prompt = f"""
            Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø²ÛŒØ± Ø±Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‡ÛŒØ¯:
            - Ø§Ù…Ù„Ø§ Ùˆ Ú¯Ø±Ø§Ù…Ø± Ø±Ø§ ØªØµØ­ÛŒØ­ Ú©Ù†ÛŒØ¯
            - Ø³Ø§Ø®ØªØ§Ø± Ø¬Ù…Ù„Ø§Øª Ø±Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‡ÛŒØ¯
            - ÙˆØ¶ÙˆØ­ Ùˆ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯
            
            Ù…ØªÙ†: {content}
            """
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",  # the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
                messages=[{"role": "user", "content": prompt}],
                max_tokens=800,
                temperature=0.4
            )
            
            result = response.choices[0].message.content
            return f"âœ¨ **Ù…ØªÙ† Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡:**\n\n{result}"
            
        except Exception as e:
            return f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ù‡Ø¨ÙˆØ¯ Ù…ØªÙ†: {str(e)}"
    
    def _execute_conversion_task(self, content: str) -> str:
        """Execute conversion task."""
        try:
            prompt = f"""
            Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø²ÛŒØ± Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒØ¯:
            - ÙØ±Ù…ØªØŒ Ø³Ø§Ø®ØªØ§Ø± ÛŒØ§ Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§ Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯
            - Ø­ÙØ¸ Ù…Ø¹Ù†Ø§ Ùˆ Ù…ÙÙ‡ÙˆÙ… Ø§ØµÙ„ÛŒ
            
            Ù…ØªÙ†: {content}
            """
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",  # the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
                messages=[{"role": "user", "content": prompt}],
                max_tokens=700,
                temperature=0.5
            )
            
            result = response.choices[0].message.content
            return f"ğŸ”„ **Ù…ØªÙ† ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯Ù‡:**\n\n{result}"
            
        except Exception as e:
            return f"Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„: {str(e)}"
    
    def _execute_generation_task(self, content: str) -> str:
        """Execute content generation task."""
        try:
            prompt = f"""
            Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ÙˆØ¶ÙˆØ¹ Ø²ÛŒØ±ØŒ Ù…Ø­ØªÙˆØ§ÛŒ Ù…ÙÛŒØ¯ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯:
            - Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ùˆ Ù…ÙÛŒØ¯ Ø¨Ø§Ø´Ø¯
            - Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø§Ø³Ø¨ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
            - Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø¨Ø§Ø´Ø¯
            
            Ù…ÙˆØ¶ÙˆØ¹: {content}
            """
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",  # the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
                messages=[{"role": "user", "content": prompt}],
                max_tokens=900,
                temperature=0.8
            )
            
            result = response.choices[0].message.content
            return f"ğŸ¯ **Ù…Ø­ØªÙˆØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡:**\n\n{result}"
            
        except Exception as e:
            return f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§: {str(e)}"
    
    def _execute_sentiment_task(self, content: str) -> str:
        """Execute sentiment analysis task using TextBlob."""
        try:
            # Analyze sentiment using TextBlob
            sentiment_result = self.analyze_sentiment(content)
            
            # Create detailed response
            blob = TextBlob(content)
            polarity = blob.sentiment.polarity
            subjectivity = blob.sentiment.subjectivity
            
            # Create emoji based on sentiment
            sentiment_emoji = {
                "Ù…Ø«Ø¨Øª": "ğŸ˜Š",
                "Ù…Ù†ÙÛŒ": "ğŸ˜", 
                "Ø®Ù†Ø«ÛŒ": "ğŸ˜"
            }
            
            result = f"""**ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù…ØªÙ†:**

ğŸ“ **Ù…ØªÙ†:** {content}

{sentiment_emoji.get(sentiment_result, "ğŸ¤”")} **Ù†ØªÛŒØ¬Ù‡:** {sentiment_result}

ğŸ“Š **Ø¬Ø²Ø¦ÛŒØ§Øª ØªØ­Ù„ÛŒÙ„:**
â€¢ Ù…ÛŒØ²Ø§Ù† Ø§Ø­Ø³Ø§Ø³ (Polarity): {polarity:.3f} (Ø§Ø² -1 ØªØ§ +1)
â€¢ Ù…ÛŒØ²Ø§Ù† Ø°Ù‡Ù†ÛŒâ€ŒØ¨ÙˆØ¯Ù† (Subjectivity): {subjectivity:.3f} (Ø§Ø² 0 ØªØ§ 1)

ğŸ“‹ **ØªÙˆØ¶ÛŒØ­:**
â€¢ Ù…Ø«Ø¨Øª: Ø§Ø­Ø³Ø§Ø³ Ø®ÙˆØ´Ø­Ø§Ù„ÛŒØŒ Ø±Ø¶Ø§ÛŒØª ÛŒØ§ Ù…Ø·Ù„ÙˆØ¨ÛŒØª
â€¢ Ù…Ù†ÙÛŒ: Ø§Ø­Ø³Ø§Ø³ Ù†Ø§Ø±Ø§Ø­ØªÛŒØŒ Ù†Ø§Ø±Ø¶Ø§ÛŒØªÛŒ ÛŒØ§ Ù†Ø§Ù…Ø·Ù„ÙˆØ¨ÛŒØª  
â€¢ Ø®Ù†Ø«ÛŒ: Ø§Ø­Ø³Ø§Ø³ Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø¨Ø¯ÙˆÙ† Ú¯Ø±Ø§ÛŒØ´ Ø®Ø§Øµ"""
            
            return result
            
        except Exception as e:
            return f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª: {str(e)}"
    
    def analyze_sentiment(self, text: str) -> str:
        """
        Analyze sentiment of text using TextBlob.
        
        Args:
            text (str): Input text to analyze
            
        Returns:
            str: Sentiment label in Persian ("Ù…Ø«Ø¨Øª", "Ù…Ù†ÙÛŒ", "Ø®Ù†Ø«ÛŒ")
        """
        try:
            blob = TextBlob(text)
            polarity = blob.sentiment.polarity
            
            if polarity > 0.1:
                return "Ù…Ø«Ø¨Øª"
            elif polarity < -0.1:
                return "Ù…Ù†ÙÛŒ"
            else:
                return "Ø®Ù†Ø«ÛŒ"
                
        except Exception as e:
            self.log(f"Error in sentiment analysis: {e}", level="error")
            return "Ø®Ù†Ø«ÛŒ"
    
    def _execute_general_task(self, message: str) -> str:
        """Execute general task when specific type is not identified."""
        try:
            prompt = f"""
            Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ùˆ Ø§Ø¨Ø²Ø§Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ù‡Ø³ØªÛŒØ¯.
            Ù„Ø·ÙØ§Ù‹ Ø¨Ù‡ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø²ÛŒØ± Ù¾Ø§Ø³Ø® Ù…ÙÛŒØ¯ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø¯Ù‡ÛŒØ¯:
            
            {message}
            """
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",  # the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
                messages=[{"role": "user", "content": prompt}],
                max_tokens=800,
                temperature=0.7
            )
            
            result = response.choices[0].message.content
            return f"ğŸ”§ **Ù¾Ø§Ø³Ø® Ø§Ø¨Ø²Ø§Ø±:**\n\n{result}"
            
        except Exception as e:
            return f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¹Ù…ÙˆÙ…ÛŒ: {str(e)}"
    
    def _get_current_timestamp(self) -> str:
        """Get current timestamp in ISO format."""
        return datetime.now().isoformat()
    
    def get_capabilities(self) -> List[str]:
        """Get list of agent capabilities."""
        return [
            "Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†",
            "ØªØ±Ø¬Ù…Ù‡ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡", 
            "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª",
            "ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§",
            "Ø¨Ù‡Ø¨ÙˆØ¯ Ù…ØªÙ†",
            "ØªØ¨Ø¯ÛŒÙ„ ÙØ±Ù…Øª",
            "ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§",
            "ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª",
            "Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¹Ù…ÙˆÙ…ÛŒ"
        ]
    
    def get_task_statistics(self) -> Dict[str, Any]:
        """Get statistics about processed tasks."""
        # This could be enhanced to track actual statistics
        return {
            "supported_tasks": len(self.task_types),
            "total_capabilities": len(self.get_capabilities()),
            "language_support": ["ÙØ§Ø±Ø³ÛŒ", "English"],
            "processing_modes": ["Ø®Ù„Ø§ØµÙ‡", "ØªØ±Ø¬Ù…Ù‡", "ØªØ­Ù„ÛŒÙ„", "Ø¨Ù‡Ø¨ÙˆØ¯", "ØªØ¨Ø¯ÛŒÙ„", "ØªÙˆÙ„ÛŒØ¯", "Ø§Ø­Ø³Ø§Ø³Ø§Øª"]
        }