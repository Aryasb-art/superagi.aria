"""
Knowledge Graph Agent for extracting concepts, relationships, and building knowledge graphs.
"""

import os
import re
import json
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from sqlalchemy import Column, Integer, String, Text, DateTime, func, create_engine, desc, JSON
from sqlalchemy.orm import sessionmaker

from .base_agent import BaseAgent
from database import Base, engine, SessionLocal


class KnowledgeGraph(Base):
    """Database model for storing knowledge graph concepts and relationships."""
    __tablename__ = "knowledge_graph"
    
    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, nullable=True)  # Can be null for anonymous users
    source_text = Column(Text, nullable=False)  # Original text
    concepts = Column(JSON, nullable=False)  # List of extracted concepts
    relationships = Column(JSON, nullable=False)  # List of relationships between concepts
    graph_data = Column(JSON, nullable=False)  # Complete graph structure for visualization
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())


class KnowledgeGraphAgent(BaseAgent):
    """
    Knowledge Graph Agent that extracts concepts, identifies relationships, 
    and builds comprehensive knowledge graphs from text input.
    """
    
    def __init__(self):
        super().__init__("KnowledgeGraphAgent", "Ø³Ø§Ø²Ù†Ø¯Ù‡ Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ Ùˆ ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø±ÙˆØ§Ø¨Ø· Ù…ÙÙ‡ÙˆÙ…ÛŒ")
        self.log("Initialized with PostgreSQL database integration for knowledge graph storage")
        
        # Create table if it doesn't exist
        self._create_knowledge_graph_table()
        
        # Initialize OpenAI client if available
        self.openai_client = None
        self._initialize_openai()
        
        # Relationship types in Persian
        self.relationship_types = {
            "Ø¹Ù„Øª_Ù…Ø¹Ù„ÙˆÙ„": ["Ø¨Ø§Ø¹Ø«", "Ù…Ù†Ø¬Ø± Ø¨Ù‡", "Ø¯Ù„ÛŒÙ„", "Ù†ØªÛŒØ¬Ù‡", "Ú†ÙˆÙ†", "Ø²ÛŒØ±Ø§"],
            "Ø´Ø§Ù…Ù„": ["Ø´Ø§Ù…Ù„", "Ø¯Ø±Ø¨Ø±Ú¯ÛŒØ±Ù†Ø¯Ù‡", "Ø­Ø§ÙˆÛŒ", "Ù…ØªØ´Ú©Ù„ Ø§Ø²"],
            "Ù…Ø±ØªØ¨Ø·": ["Ù…Ø±ØªØ¨Ø·", "ÙˆØ§Ø¨Ø³ØªÙ‡", "Ù…ØªØµÙ„", "Ù…Ø±Ø¨ÙˆØ·"],
            "Ù…Ø´Ø§Ø¨Ù‡": ["Ù…Ø«Ù„", "Ø´Ø¨ÛŒÙ‡", "Ù‡Ù…Ø§Ù†Ù†Ø¯", "Ù…Ø§Ù†Ù†Ø¯"],
            "Ù…ØªØ¶Ø§Ø¯": ["Ù…Ø®Ø§Ù„Ù", "Ø¨Ø±Ø¹Ú©Ø³", "Ù…ØªØ¶Ø§Ø¯", "Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„"],
            "Ø²Ù…Ø§Ù†ÛŒ": ["Ù‚Ø¨Ù„ Ø§Ø²", "Ø¨Ø¹Ø¯ Ø§Ø²", "Ù‡Ù…Ø²Ù…Ø§Ù†", "Ø¯Ø± Ø·ÙˆÙ„"],
            "Ù…Ú©Ø§Ù†ÛŒ": ["Ø¯Ø±", "Ø±ÙˆÛŒ", "Ø²ÛŒØ±", "Ú©Ù†Ø§Ø±", "Ù†Ø²Ø¯ÛŒÚ©"]
        }
        
        # Important concept indicators
        self.concept_indicators = [
            "Ù…ÙÙ‡ÙˆÙ…", "Ø§ÛŒØ¯Ù‡", "Ù†Ø¸Ø±ÛŒÙ‡", "Ø±ÙˆØ´", "Ø³ÛŒØ³ØªÙ…", "ÙØ±Ø¢ÛŒÙ†Ø¯", "Ù‡Ø¯Ù", "Ù…Ø´Ú©Ù„",
            "Ø±Ø§Ù‡â€ŒØ­Ù„", "Ù†ØªÛŒØ¬Ù‡", "Ø¹Ø§Ù…Ù„", "Ø¬Ù†Ø¨Ù‡", "ÙˆÛŒÚ˜Ú¯ÛŒ", "Ø®ØµÙˆØµÛŒØª", "Ø¹Ù†ØµØ±"
        ]
        
        self.log("Knowledge graph relationship types and concept indicators initialized")
    
    def _create_knowledge_graph_table(self):
        """Create knowledge_graph table if it doesn't exist."""
        try:
            Base.metadata.create_all(bind=engine)
            self.log("Knowledge graph table ready")
        except Exception as e:
            self.log(f"Error creating knowledge graph table: {e}", level="error")
    
    def _initialize_openai(self):
        """Initialize OpenAI client if API key is available."""
        try:
            import openai
            api_key = os.environ.get("OPENAI_API_KEY")
            if api_key:
                self.openai_client = openai.OpenAI(api_key=api_key)
                self.log("OpenAI GPT integration ready for concept extraction")
            else:
                self.log("OpenAI API key not found, using fallback methods")
        except ImportError:
            self.log("OpenAI library not available, using fallback methods")
        except Exception as e:
            self.log(f"OpenAI initialization error: {e}, using fallback methods")
    
    def respond(self, message: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Process knowledge graph requests and generate response.
        
        Args:
            message (str): The message containing knowledge graph analysis request
            context (Dict): Optional context information
            
        Returns:
            Dict: Response containing the knowledge graph analysis result
        """
        try:
            self.log(f"Processing knowledge graph request: {message[:100]}...")
            
            # Remember the user message
            self.remember(message)
            
            # Detect operation type
            operation = self._detect_operation(message)
            
            if operation == "build":
                result = self._build_knowledge_graph(message, context)
                return {"response": result.get("response", "")}
            elif operation == "search":
                result = self._search_knowledge_graph(message, context)
                return {"response": result.get("response", "")}
            elif operation == "list":
                result = self._list_knowledge_graphs(message, context)
                return {"response": result.get("response", "")}
            else:
                # Default: build knowledge graph from the message
                result = self._build_knowledge_graph(message, context)
                return {"response": result.get("response", "")}
                
        except Exception as e:
            self.log(f"Error processing knowledge graph request: {e}", level="error")
            return {
                "response": f"âŒ **Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´:** {str(e)}"
            }
    
    def _detect_operation(self, message: str) -> str:
        """Detect the type of knowledge graph operation requested."""
        message_lower = message.lower()
        
        build_keywords = ["ØªØ­Ù„ÛŒÙ„", "analyze", "Ú¯Ø±Ø§Ù", "graph", "Ø³Ø§Ø®Øª", "build", "Ø§Ø³ØªØ®Ø±Ø§Ø¬", "extract"]
        search_keywords = ["Ø¬Ø³ØªØ¬Ùˆ", "search", "ÛŒØ§ÙØªÙ†", "find", "Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ", "retrieve"]
        list_keywords = ["Ù„ÛŒØ³Øª", "list", "Ù†Ù…Ø§ÛŒØ´", "show", "Ù‡Ù…Ù‡", "all"]
        
        if any(keyword in message_lower for keyword in search_keywords):
            return "search"
        elif any(keyword in message_lower for keyword in list_keywords):
            return "list"
        elif any(keyword in message_lower for keyword in build_keywords):
            return "build"
        else:
            return "build"
    
    def _build_knowledge_graph(self, message: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Build knowledge graph from input text."""
        try:
            user_id = context.get("user_id") if context else None
            
            # Extract concepts from the text
            concepts = self._extract_concepts(message)
            
            if not concepts:
                return {
                    "response": "ğŸ“Š **ØªØ­Ù„ÛŒÙ„ Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´:** Ù‡ÛŒÚ† Ù…ÙÙ‡ÙˆÙ… Ù‚Ø§Ø¨Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.",
                    "success": True,
                    "timestamp": self._get_current_timestamp()
                }
            
            # Identify relationships between concepts
            relationships = self._identify_relationships(message, concepts)
            
            # Build graph structure
            graph_data = self._build_graph_structure(concepts, relationships)
            
            # Save to database
            graph_id = self._save_knowledge_graph(
                user_id, message, concepts, relationships, graph_data
            )
            
            response = self._format_knowledge_graph_response(
                concepts, relationships, graph_data, graph_id
            )
            
            return {
                "response": response,
                "success": True,
                "concepts_count": len(concepts),
                "relationships_count": len(relationships),
                "graph_id": graph_id,
                "timestamp": self._get_current_timestamp()
            }
            
        except Exception as e:
            self.log(f"Error building knowledge graph: {e}", level="error")
            return {
                "response": f"âŒ **Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´:** {str(e)}",
                "success": False,
                "error": str(e),
                "timestamp": self._get_current_timestamp()
            }
    
    def _extract_concepts(self, text: str) -> List[Dict[str, Any]]:
        """Extract important concepts from text using OpenAI or fallback methods."""
        if self.openai_client:
            return self._extract_concepts_with_openai(text)
        else:
            return self._extract_concepts_fallback(text)
    
    def _extract_concepts_with_openai(self, text: str) -> List[Dict[str, Any]]:
        """Extract concepts using OpenAI GPT."""
        try:
            prompt = f"""
            Ø§Ø² Ù…ØªÙ† Ø²ÛŒØ± Ù…ÙØ§Ù‡ÛŒÙ… Ù…Ù‡Ù… Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù† Ùˆ Ù‡Ø± Ù…ÙÙ‡ÙˆÙ… Ø±Ø§ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ± Ø¯Ø± Ù‚Ø§Ù„Ø¨ JSON Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†:
            - concept: Ù†Ø§Ù… Ù…ÙÙ‡ÙˆÙ…
            - type: Ù†ÙˆØ¹ Ù…ÙÙ‡ÙˆÙ… (Ø´Ø®ØµØŒ Ù…Ú©Ø§Ù†ØŒ Ø´ÛŒØ¡ØŒ Ø§ÛŒØ¯Ù‡ØŒ ÙØ±Ø¢ÛŒÙ†Ø¯ØŒ Ù‡Ø¯ÙØŒ Ù…Ø´Ú©Ù„ØŒ Ø±Ø§Ù‡â€ŒØ­Ù„)
            - importance: Ø§Ù‡Ù…ÛŒØª Ø§Ø² 1 ØªØ§ 5
            - description: ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡
            
            Ù…ØªÙ†: {text}
            
            ÙÙ‚Ø· JSON Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†:
            """
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",  # the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            concepts = result.get("concepts", [])
            
            self.log(f"OpenAI extracted {len(concepts)} concepts")
            return concepts
            
        except Exception as e:
            self.log(f"OpenAI concept extraction failed: {e}, using fallback")
            return self._extract_concepts_fallback(text)
    
    def _extract_concepts_fallback(self, text: str) -> List[Dict[str, Any]]:
        """Extract concepts using rule-based approach."""
        concepts = []
        
        # Split text into sentences
        sentences = re.split(r'[.!?ØŸ]', text)
        
        # Extract noun phrases and important words
        concept_candidates = set()
        
        for sentence in sentences:
            # Find words that might be concepts
            words = re.findall(r'\b\w+\b', sentence)
            
            # Look for concept indicators
            for i, word in enumerate(words):
                if word in self.concept_indicators and i + 1 < len(words):
                    concept_candidates.add(words[i + 1])
                
                # Add significant nouns (longer than 3 characters)
                if len(word) > 3 and word not in ['Ø§Ø³Øª', 'Ø¨Ø§ÛŒØ¯', 'Ù…ÛŒâ€ŒÚ©Ù†Ø¯', 'Ø¯Ø§Ø±Ø¯']:
                    concept_candidates.add(word)
        
        # Convert candidates to concept objects
        for candidate in list(concept_candidates)[:10]:  # Limit to top 10
            concepts.append({
                "concept": candidate,
                "type": self._categorize_concept(candidate),
                "importance": self._calculate_importance(candidate, text),
                "description": f"Ù…ÙÙ‡ÙˆÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡: {candidate}"
            })
        
        self.log(f"Fallback method extracted {len(concepts)} concepts")
        return concepts
    
    def _categorize_concept(self, concept: str) -> str:
        """Categorize a concept based on its characteristics."""
        concept_lower = concept.lower()
        
        if any(word in concept_lower for word in ['Ù‡Ø¯Ù', 'Ø¢Ø±Ø²Ùˆ', 'Ø¨Ø±Ù†Ø§Ù…Ù‡']):
            return "Ù‡Ø¯Ù"
        elif any(word in concept_lower for word in ['Ù…Ø´Ú©Ù„', 'Ù…Ø³Ø¦Ù„Ù‡', 'Ú†Ø§Ù„Ø´']):
            return "Ù…Ø´Ú©Ù„"
        elif any(word in concept_lower for word in ['Ø±Ø§Ù‡â€ŒØ­Ù„', 'Ø­Ù„', 'Ù¾Ø§Ø³Ø®']):
            return "Ø±Ø§Ù‡â€ŒØ­Ù„"
        elif any(word in concept_lower for word in ['ÙØ±Ø¢ÛŒÙ†Ø¯', 'Ø±ÙˆØ´', 'ØªÚ©Ù†ÛŒÚ©']):
            return "ÙØ±Ø¢ÛŒÙ†Ø¯"
        elif any(word in concept_lower for word in ['Ø´Ø®Øµ', 'ÙØ±Ø¯', 'Ú©Ø³']):
            return "Ø´Ø®Øµ"
        elif any(word in concept_lower for word in ['Ù…Ú©Ø§Ù†', 'Ø¬Ø§', 'Ù…Ø­Ù„']):
            return "Ù…Ú©Ø§Ù†"
        else:
            return "Ø§ÛŒØ¯Ù‡"
    
    def _calculate_importance(self, concept: str, text: str) -> int:
        """Calculate importance score for a concept."""
        # Count frequency
        frequency = text.lower().count(concept.lower())
        
        # Length factor
        length_factor = min(len(concept) / 5, 2)
        
        # Calculate score
        score = min(int(frequency + length_factor), 5)
        return max(score, 1)
    
    def _identify_relationships(self, text: str, concepts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Identify relationships between concepts."""
        relationships = []
        
        if len(concepts) < 2:
            return relationships
        
        # Check for relationships using pattern matching
        for i, concept1 in enumerate(concepts):
            for j, concept2 in enumerate(concepts[i+1:], i+1):
                relationship = self._find_relationship(text, concept1, concept2)
                if relationship:
                    relationships.append(relationship)
        
        self.log(f"Identified {len(relationships)} relationships")
        return relationships
    
    def _find_relationship(self, text: str, concept1: Dict[str, Any], concept2: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Find relationship between two concepts in text."""
        text_lower = text.lower()
        name1 = concept1["concept"].lower()
        name2 = concept2["concept"].lower()
        
        # Look for both concepts in same sentence
        sentences = re.split(r'[.!?ØŸ]', text_lower)
        
        for sentence in sentences:
            if name1 in sentence and name2 in sentence:
                # Check for relationship indicators
                for rel_type, keywords in self.relationship_types.items():
                    for keyword in keywords:
                        if keyword in sentence:
                            return {
                                "source": concept1["concept"],
                                "target": concept2["concept"],
                                "relationship": rel_type,
                                "description": f"{concept1['concept']} {keyword} {concept2['concept']}",
                                "confidence": 0.8,
                                "context": sentence.strip()
                            }
                
                # Default relationship if concepts appear together
                return {
                    "source": concept1["concept"],
                    "target": concept2["concept"],
                    "relationship": "Ù…Ø±ØªØ¨Ø·",
                    "description": f"{concept1['concept']} Ù…Ø±ØªØ¨Ø· Ø¨Ø§ {concept2['concept']}",
                    "confidence": 0.5,
                    "context": sentence.strip()
                }
        
        return None
    
    def _build_graph_structure(self, concepts: List[Dict[str, Any]], relationships: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Build graph structure for visualization."""
        nodes = []
        edges = []
        
        # Add nodes
        for concept in concepts:
            nodes.append({
                "id": concept["concept"],
                "label": concept["concept"],
                "type": concept["type"],
                "importance": concept["importance"],
                "description": concept["description"]
            })
        
        # Add edges
        for rel in relationships:
            edges.append({
                "source": rel["source"],
                "target": rel["target"],
                "relationship": rel["relationship"],
                "label": rel["relationship"],
                "confidence": rel["confidence"],
                "description": rel["description"]
            })
        
        return {
            "nodes": nodes,
            "edges": edges,
            "metadata": {
                "total_concepts": len(concepts),
                "total_relationships": len(relationships),
                "created_at": self._get_current_timestamp()
            }
        }
    
    def _save_knowledge_graph(self, user_id: Optional[int], source_text: str, 
                            concepts: List[Dict], relationships: List[Dict], 
                            graph_data: Dict[str, Any]) -> int:
        """Save knowledge graph to database."""
        try:
            db = SessionLocal()
            
            knowledge_graph = KnowledgeGraph(
                user_id=user_id,
                source_text=source_text,
                concepts=concepts,
                relationships=relationships,
                graph_data=graph_data
            )
            
            db.add(knowledge_graph)
            db.commit()
            db.refresh(knowledge_graph)
            
            graph_id = knowledge_graph.id
            self.log(f"Knowledge graph saved with ID: {graph_id}")
            
            db.close()
            return graph_id
            
        except Exception as e:
            self.log(f"Error saving knowledge graph: {e}", level="error")
            return 0
    
    def _search_knowledge_graph(self, query: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Search for concepts in existing knowledge graphs."""
        try:
            user_id = context.get("user_id") if context else None
            search_term = self._extract_search_term(query)
            
            db = SessionLocal()
            
            # Search in concepts and relationships
            query_db = db.query(KnowledgeGraph)
            if user_id:
                query_db = query_db.filter(KnowledgeGraph.user_id == user_id)
            
            graphs = query_db.order_by(desc(KnowledgeGraph.created_at)).limit(20).all()
            
            matching_graphs = []
            for graph in graphs:
                if self._graph_matches_search(graph, search_term):
                    matching_graphs.append({
                        "id": graph.id,
                        "source_text": graph.source_text[:100] + "..." if len(graph.source_text) > 100 else graph.source_text,
                        "concepts_count": len(graph.concepts),
                        "relationships_count": len(graph.relationships),
                        "created_at": graph.created_at.isoformat() if graph.created_at else None
                    })
            
            db.close()
            
            response = self._format_search_response(matching_graphs, search_term)
            
            return {
                "response": response,
                "success": True,
                "results_count": len(matching_graphs),
                "timestamp": self._get_current_timestamp()
            }
            
        except Exception as e:
            self.log(f"Error searching knowledge graphs: {e}", level="error")
            return {
                "response": f"âŒ **Ø®Ø·Ø§ Ø¯Ø± Ø¬Ø³ØªØ¬ÙˆÛŒ Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´:** {str(e)}",
                "success": False,
                "error": str(e),
                "timestamp": self._get_current_timestamp()
            }
    
    def _extract_search_term(self, query: str) -> str:
        """Extract search term from query."""
        # Remove common words and extract meaningful terms
        stop_words = {'Ø¬Ø³ØªØ¬Ùˆ', 'ÛŒØ§ÙØªÙ†', 'Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ', 'search', 'find', 'Ø¯Ø±', 'Ø¨Ø±Ø§ÛŒ', 'Ø§Ø²'}
        words = re.findall(r'\b\w+\b', query.lower())
        meaningful_words = [word for word in words if word not in stop_words and len(word) > 2]
        return ' '.join(meaningful_words[:3])  # Top 3 meaningful words
    
    def _graph_matches_search(self, graph: KnowledgeGraph, search_term: str) -> bool:
        """Check if a graph matches the search term."""
        search_lower = search_term.lower()
        
        # Check source text
        if search_lower in graph.source_text.lower():
            return True
        
        # Check concepts
        for concept in graph.concepts:
            if search_lower in concept.get("concept", "").lower():
                return True
        
        # Check relationships
        for rel in graph.relationships:
            if (search_lower in rel.get("source", "").lower() or 
                search_lower in rel.get("target", "").lower()):
                return True
        
        return False
    
    def _list_knowledge_graphs(self, message: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """List recent knowledge graphs."""
        try:
            user_id = context.get("user_id") if context else None
            limit = self._extract_limit(message)
            
            db = SessionLocal()
            
            query = db.query(KnowledgeGraph)
            if user_id:
                query = query.filter(KnowledgeGraph.user_id == user_id)
            
            graphs = query.order_by(desc(KnowledgeGraph.created_at)).limit(limit).all()
            
            graph_list = []
            for graph in graphs:
                graph_list.append({
                    "id": graph.id,
                    "source_text": graph.source_text[:80] + "..." if len(graph.source_text) > 80 else graph.source_text,
                    "concepts_count": len(graph.concepts),
                    "relationships_count": len(graph.relationships),
                    "created_at": graph.created_at.isoformat() if graph.created_at else None
                })
            
            db.close()
            
            response = self._format_list_response(graph_list)
            
            return {
                "response": response,
                "success": True,
                "graphs": graph_list,
                "count": len(graph_list),
                "timestamp": self._get_current_timestamp()
            }
            
        except Exception as e:
            self.log(f"Error listing knowledge graphs: {e}", level="error")
            return {
                "response": f"âŒ **Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ø´:** {str(e)}",
                "success": False,
                "error": str(e),
                "timestamp": self._get_current_timestamp()
            }
    
    def _extract_limit(self, message: str) -> int:
        """Extract limit number from message."""
        import re
        numbers = re.findall(r'\d+', message)
        return int(numbers[0]) if numbers else 10
    
    def _format_knowledge_graph_response(self, concepts: List[Dict], relationships: List[Dict], 
                                       graph_data: Dict[str, Any], graph_id: int) -> str:
        """Format the knowledge graph analysis response."""
        response = f"ğŸ§  **Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯!** (ğŸ†” #{graph_id})\n\n"
        
        # Concepts section
        response += f"**ğŸ“Š Ù…ÙØ§Ù‡ÛŒÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡** ({len(concepts)} Ù…ÙˆØ±Ø¯):\n"
        for i, concept in enumerate(concepts[:5], 1):
            importance_stars = "â­" * concept.get("importance", 1)
            response += f"**{i}.** {self._get_concept_emoji(concept.get('type', ''))} `{concept.get('type', 'Ù†Ø§Ù…Ø´Ø®Øµ')}` - {concept.get('concept', '')}\n"
            response += f"   {importance_stars} Ø§Ù‡Ù…ÛŒØª: {concept.get('importance', 1)}/5\n\n"
        
        if len(concepts) > 5:
            response += f"... Ùˆ {len(concepts) - 5} Ù…ÙÙ‡ÙˆÙ… Ø¯ÛŒÚ¯Ø±\n\n"
        
        # Relationships section
        if relationships:
            response += f"**ğŸ”— Ø±ÙˆØ§Ø¨Ø· Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡** ({len(relationships)} Ù…ÙˆØ±Ø¯):\n"
            for i, rel in enumerate(relationships[:5], 1):
                confidence_percent = int(rel.get("confidence", 0.5) * 100)
                response += f"**{i}.** {rel.get('source', '')} âœ `{rel.get('relationship', '')}` âœ {rel.get('target', '')}\n"
                response += f"   ğŸ“Š Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {confidence_percent}% | ğŸ“ {rel.get('description', '')}\n\n"
            
            if len(relationships) > 5:
                response += f"... Ùˆ {len(relationships) - 5} Ø±Ø§Ø¨Ø·Ù‡ Ø¯ÛŒÚ¯Ø±\n\n"
        else:
            response += "**ğŸ”— Ø±ÙˆØ§Ø¨Ø·:** Ù‡ÛŒÚ† Ø±Ø§Ø¨Ø·Ù‡â€ŒØ§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯.\n\n"
        
        # Graph statistics
        response += f"**ğŸ“ˆ Ø¢Ù…Ø§Ø± Ú¯Ø±Ø§Ù:**\n"
        response += f"â€¢ ØªØ¹Ø¯Ø§Ø¯ Ú¯Ø±Ù‡â€ŒÙ‡Ø§: {len(concepts)}\n"
        response += f"â€¢ ØªØ¹Ø¯Ø§Ø¯ ÛŒØ§Ù„â€ŒÙ‡Ø§: {len(relationships)}\n"
        response += f"â€¢ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ú¯Ø±Ø§Ù: {'Ø³Ø§Ø¯Ù‡' if len(relationships) < 3 else 'Ù…ØªÙˆØ³Ø·' if len(relationships) < 8 else 'Ù¾ÛŒÚ†ÛŒØ¯Ù‡'}\n\n"
        
        response += "ğŸ’¡ **Ù†Ú©ØªÙ‡:** Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø§Ø² Ø¯Ø³ØªÙˆØ± 'Ø¬Ø³ØªØ¬ÙˆÛŒ Ú¯Ø±Ø§Ù' Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
        
        return response
    
    def _format_search_response(self, matching_graphs: List[Dict], search_term: str) -> str:
        """Format the search results response."""
        response = f"ğŸ” **Ù†ØªØ§ÛŒØ¬ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ: \"{search_term}\"** ({len(matching_graphs)} Ù…ÙˆØ±Ø¯)\n\n"
        
        if matching_graphs:
            for i, graph in enumerate(matching_graphs[:5], 1):
                response += f"**{i}.** ğŸ“Š Ú¯Ø±Ø§Ù #{graph['id']}\n"
                response += f"   **Ù…ØªÙ†:** {graph['source_text']}\n"
                response += f"   ğŸ§  Ù…ÙØ§Ù‡ÛŒÙ…: {graph['concepts_count']} | ğŸ”— Ø±ÙˆØ§Ø¨Ø·: {graph['relationships_count']}\n"
                response += f"   ğŸ•’ {graph['created_at'][:19].replace('T', ' ')}\n\n"
            
            if len(matching_graphs) > 5:
                response += f"... Ùˆ {len(matching_graphs) - 5} Ù†ØªÛŒØ¬Ù‡ Ø¯ÛŒÚ¯Ø±\n\n"
        else:
            response += "âŒ **Ù‡ÛŒÚ† Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.**\n\n"
        
        response += "ğŸ’¡ **Ø±Ø§Ù‡Ù†Ù…Ø§:** Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ú¯Ø±Ø§Ù Ø¬Ø¯ÛŒØ¯ØŒ Ù…ØªÙ† Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯."
        
        return response
    
    def _format_list_response(self, graphs: List[Dict]) -> str:
        """Format the graphs list response."""
        response = f"ğŸ“š **Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ø´ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡** ({len(graphs)} Ù…ÙˆØ±Ø¯):\n\n"
        
        if graphs:
            for i, graph in enumerate(graphs, 1):
                response += f"**{i}.** ğŸ§  Ú¯Ø±Ø§Ù #{graph['id']}\n"
                response += f"   **Ù…ØªÙ†:** {graph['source_text']}\n"
                response += f"   ğŸ“Š Ù…ÙØ§Ù‡ÛŒÙ…: {graph['concepts_count']} | ğŸ”— Ø±ÙˆØ§Ø¨Ø·: {graph['relationships_count']}\n"
                response += f"   ğŸ•’ {graph['created_at'][:19].replace('T', ' ')}\n\n"
        else:
            response += "ğŸ“­ **Ù‡Ù†ÙˆØ² Ù‡ÛŒÚ† Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ÛŒ Ø³Ø§Ø®ØªÙ‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.**\n\n"
        
        response += "ğŸ’¡ **Ø±Ø§Ù‡Ù†Ù…Ø§:** Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ú¯Ø±Ø§Ù Ø¬Ø¯ÛŒØ¯ØŒ Ù…ØªÙ† Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯."
        
        return response
    
    def _get_concept_emoji(self, concept_type: str) -> str:
        """Get emoji for concept type."""
        concept_emojis = {
            "Ù‡Ø¯Ù": "ğŸ¯",
            "Ù…Ø´Ú©Ù„": "â—",
            "Ø±Ø§Ù‡â€ŒØ­Ù„": "ğŸ’¡",
            "ÙØ±Ø¢ÛŒÙ†Ø¯": "âš™ï¸",
            "Ø´Ø®Øµ": "ğŸ‘¤",
            "Ù…Ú©Ø§Ù†": "ğŸ“",
            "Ø§ÛŒØ¯Ù‡": "ğŸ’­",
            "Ø´ÛŒØ¡": "ğŸ“¦"
        }
        return concept_emojis.get(concept_type, "ğŸ”¸")
    
    def _get_current_timestamp(self) -> str:
        """Get current timestamp in ISO format."""
        return datetime.now().isoformat()
    
    def get_capabilities(self) -> list:
        """Get list of agent capabilities."""
        return [
            "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙØ§Ù‡ÛŒÙ… Ø§Ø² Ù…ØªÙ†",
            "ØªØ´Ø®ÛŒØµ Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒÙ† Ù…ÙØ§Ù‡ÛŒÙ…",
            "Ø³Ø§Ø®Øª Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ Ø³Ø§Ø®ØªØ§Ø±ÛŒ",
            "Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø±Ø§Ù Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³",
            "Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯",
            "Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±ÛŒ Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§"
        ]
    
    def get_database_stats(self) -> Dict[str, Any]:
        """Get database statistics for knowledge graphs."""
        try:
            db = SessionLocal()
            
            total_graphs = db.query(KnowledgeGraph).count()
            recent_graphs = db.query(KnowledgeGraph).filter(
                KnowledgeGraph.created_at >= datetime.now().replace(hour=0, minute=0, second=0)
            ).count()
            
            # Get average concepts and relationships
            graphs = db.query(KnowledgeGraph).all()
            avg_concepts = sum(len(g.concepts) for g in graphs) / len(graphs) if graphs else 0
            avg_relationships = sum(len(g.relationships) for g in graphs) / len(graphs) if graphs else 0
            
            db.close()
            
            return {
                "total_graphs": total_graphs,
                "recent_graphs": recent_graphs,
                "avg_concepts": round(avg_concepts, 1),
                "avg_relationships": round(avg_relationships, 1),
                "table_name": "knowledge_graph"
            }
            
        except Exception as e:
            self.log(f"Error getting database stats: {e}", level="error")
            return {
                "total_graphs": 0,
                "recent_graphs": 0,
                "avg_concepts": 0,
                "avg_relationships": 0,
                "error": str(e)
            }